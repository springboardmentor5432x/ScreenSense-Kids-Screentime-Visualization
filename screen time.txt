# -------------------------------------------------------------
# SCREEN SENSE â€“ Kids Screentime Visualization
# Milestone 1: Data Foundation and Cleaning
# Week 1: Project Initialization and Dataset Setup
# -------------------------------------------------------------

# STEP 1: Import Required Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# Display settings
pd.set_option('display.max_columns', None)
pd.set_option('display.precision', 2)

print("âœ… Libraries imported successfully")

# STEP 2: Load the Dataset
# -------------------------------------------------------------
# Download the dataset from Kaggle and place in the same folder
# Kaggle URL: https://www.kaggle.com/datasets/ankushpanday2/indian-kids-screentime-2025
# Example filename: Indian_Kids_Screentime_2025.csv
# -------------------------------------------------------------
file_path = "Indian_Kids_Screentime_2025.csv"

try:
    df = pd.read_csv(file_path)
    print("âœ… Dataset loaded successfully!")
except FileNotFoundError:
    print("âŒ Dataset not found. Please check your file path.")

# STEP 3: Quick Preview of the Data
print("\nðŸ”¹ First 5 Rows of Dataset:")
display(df.head())

# STEP 4: Dataset Basic Info
print("\nðŸ”¹ Dataset Information:")
print(df.info())

print("\nðŸ”¹ Shape of Dataset:")
print(f"Rows: {df.shape[0]} | Columns: {df.shape[1]}")

# STEP 5: Summary Statistics
print("\nðŸ”¹ Summary Statistics (Numerical Columns):")
display(df.describe())

print("\nðŸ”¹ Summary Statistics (Categorical Columns):")
display(df.describe(include=['object']))

# STEP 6: Checking for Missing Values
print("\nðŸ”¹ Missing Values per Column:")
print(df.isnull().sum())

total_missing = df.isnull().sum().sum()
print(f"\nTotal Missing Values in Dataset: {total_missing}")

# STEP 7: Check for Duplicate Records
duplicates = df.duplicated().sum()
print(f"\nðŸ”¹ Duplicate Rows Found: {duplicates}")

# STEP 8: Explore Unique Values in Categorical Columns
print("\nðŸ”¹ Unique Values in Categorical Columns:")
categorical_cols = df.select_dtypes(include='object').columns

for col in categorical_cols:
    print(f"\nâ–¶ {col} ({df[col].nunique()} unique values):")
    print(df[col].unique()[:10])

# STEP 9: Quick Data Distribution Check
# Histogram for numeric columns
numeric_cols = df.select_dtypes(include=np.number).columns
df[numeric_cols].hist(bins=20, figsize=(12,6), edgecolor='black')
plt.suptitle("Distribution of Numeric Columns", fontsize=14)
plt.show()

# STEP 10: Outlier Detection â€“ Boxplot for Screen Time
plt.figure(figsize=(8,4))
sns.boxplot(x='Screen_Time', data=df, color='skyblue')
plt.title("Boxplot â€“ Screen Time (in minutes)")
plt.xlabel("Screen Time (minutes)")
plt.show()

# STEP 11: Correlation Heatmap (initial)
plt.figure(figsize=(6,4))
sns.heatmap(df.select_dtypes(include=np.number).corr(), annot=True, cmap='Blues')
plt.title("Correlation Between Numeric Variables")
plt.show()

# STEP 12: Initial Data Quality Report
report = {
    "Total Rows": df.shape[0],
    "Total Columns": df.shape[1],
    "Total Missing Values": int(total_missing),
    "Duplicate Rows": int(duplicates),
    "Numeric Columns": numeric_cols.tolist(),
    "Categorical Columns": categorical_cols.tolist()
}

report_df = pd.DataFrame(list(report.items()), columns=["Metric", "Value"])
display(report_df)

# STEP 13: Save Initial Report
report_df.to_csv("Week1_Initial_Data_Report.csv", index=False)
print("\nðŸ“ 'Week1_Initial_Data_Report.csv' saved successfully!")

# STEP 14: Record Initial Observations
print("\nâœ… INITIAL OBSERVATIONS & NOTES")
print("""
1. Dataset loaded successfully with expected columns such as:
   - Age, Gender, Location, Device_Type, Day, Activity_Category, Screen_Time.
2. Data types appear appropriate (numerical/categorical verified).
3. A few missing values may exist; to be cleaned in Week 2.
4. Screen_Time column may have outliers (> 600 mins/day).
5. Some categorical fields may have inconsistent capitalization (Urban vs urban).
6. Data appears balanced across days and categories.
7. Screen_Time assumed to be average minutes per day.
""")

print("\nðŸŽ¯ Week 1 â€“ Dataset Setup & Initial Exploration Completed Successfully!")
